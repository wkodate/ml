# Train Neural Network
メモ
* ニューラルネットワークの学習は、データからパラメータの値を決める。
* 人の考えた特徴量を使って機械学習を行っていたが、ディープラーニングでは特徴量の選定すら人を介さない
* 汎化性能を高めるために訓練データとテストデータを分ける。あるデータセットにだけ適している状態を過学習
* 損失関数は、ニューラルネットワークの性能の悪さを表す指標。2乗和誤差や交差エントロピー誤差が使われる。損失関数が最小値をとるときのパラメータ(重みとバイアス)が最適なパラメータとなる
* 勾配(gradient)は、すべての変数の偏微分をベクトルとしてまとめたもの。勾配の方向は、各地点において関数の値を最も減らす方向。
* 勾配法でどれだけパラメータを更新するかを決めるのが学習率。人の手で設定されるハイパーパラメータ
* ニューラルネットワークの学習手順
  * 前提
    * 重みとバイアスを訓練データに適応するように調整することを学習と呼ぶ
  * Step1 - ミニバッチ
    * 訓練データの中からランダムにデータを選ぶ(このデータを見にバッチと呼ぶ)
    * ランダムに選ばれたデータを使う方法を確率的勾配降下法(SGD)と呼ぶ
  * Step2 - 勾配の算出
    * ミニバッチの損失関数を減らすために、各重みパラメータの勾配を求める
  * Step3 - パラメータの更新
    * 重みパラメータを勾配方向に微小量だけ更新する
  * Step4 - 繰り返す
    * Step1-Step3を繰り返す
