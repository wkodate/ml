# Backpropagation
メモ
* 計算グラフの逆伝播で各ノードの微分を求めることができる
* ニューラルネットワークの構成要素をレイヤを使って簡単に構築することができる
  * 活性化関数レイヤにはReLU(Rectified Linear Unit)とSigmoidがある
  * 行列の積を行う処理ではAffine(アフィン)レイヤが使われる
  * 出力層にはSoftmaxレイヤが使われる。入力した値を正規化して出力する
* 誤差逆伝播は、学習で高速に勾配を求めるのに使う。数値微分は時間がかかるため、誤差逆伝搬の実装の正しさを確認するために使われる(勾配確認)
